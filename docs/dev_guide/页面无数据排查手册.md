![Logo](https://user-images.githubusercontent.com/71620349/185368586-aed82d30-1534-453d-86ff-ecfa9d0f35bd.png)

# 页面无数据排查手册


---

## 1、集群接入错误

### 1.1、异常现象

如下图所示，集群非空时，大概率为地址配置错误导致。

<img src=http://img-ys011.didistatic.com/static/dc2img/do1_BRiXBvqYFK2dxSF1aqgZ width="80%">

 

### 1.2、解决方案

接入集群时，依据提示的错误，进行相应的解决。例如：

<img src=http://img-ys011.didistatic.com/static/dc2img/do1_Yn4LhV8aeSEKX1zrrkUi width="50%">

### 1.3、正常情况

接入集群时，页面信息都自动正常出现，没有提示错误。







---

## 2、JMX连接失败

背景：Kafka 通过 JMX 服务进行运行指标的暴露，因此 `KnowStreaming` 会主动连接 Kafka 的 JMX 服务进行指标采集。如果我们发现页面缺少指标，那么可能原因之一是 Kafka 的 JMX 端口配置的有问题导致指标获取失败，进而页面没有数据。

### 2.1、正异常现象

**1、异常现象**

Broker 列表的 JMX PORT 列出现红色感叹号，则表示 JMX 连接存在异常。

<img src=http://img-ys011.didistatic.com/static/dc2img/do1_MLlLCfAktne4X6MBtBUd width="90%">


**2、正常现象**

Broker 列表的 JMX PORT 列出现绿色，则表示 JMX 连接正常。

<img src=http://img-ys011.didistatic.com/static/dc2img/do1_ymtDTCiDlzfrmSCez2lx width="90%">


---


### 2.2、异因一：JMX未开启

#### 2.2.1、异常现象

broker列表的JMX Port值为-1，对应Broker的JMX未开启。

<img src=http://img-ys011.didistatic.com/static/dc2img/do1_E1PD8tPsMeR2zYLFBFAu width="90%">

#### 2.2.2、解决方案

开启JMX，开启流程如下：

1、修改kafka的bin目录下面的：`kafka-server-start.sh`文件

```bash
# 在这个下面增加JMX端口的配置
if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"    
    export JMX_PORT=9999  # 增加这个配置, 这里的数值并不一定是要9999 
fi
```


2、修改kafka的bin目录下面对的：`kafka-run-class.sh`文件

```bash
# JMX settings 
if [ -z "$KAFKA_JMX_OPTS" ]; then
    KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=${当前机器的IP}" 
fi  

# JMX port to use 
if [  $JMX_PORT ]; then
    KAFKA_JMX_OPTS="$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT -Dcom.sun.management.jmxremote.rmi.port=$JMX_PORT" 
fi
```



3、重启Kafka-Broker。


---



### 2.3、异原二：JMX配置错误

#### 2.3.1、异常现象

错误日志：

```log
# 错误一： 错误提示的是真实的IP，这样的话基本就是JMX配置的有问题了。 
2021-01-27 10:06:20.730 ERROR 50901 --- [ics-Thread-1-62] c.x.k.m.c.utils.jmx.JmxConnectorWrap     : JMX connect exception, host:192.168.0.1 port:9999. java.rmi.ConnectException: Connection refused to host: 192.168.0.1; nested exception is:    

# 错误二：错误提示的是127.0.0.1这个IP，这个是机器的hostname配置的可能有问题。 
2021-01-27 10:06:20.730 ERROR 50901 --- [ics-Thread-1-62] c.x.k.m.c.utils.jmx.JmxConnectorWrap     : JMX connect exception, host:127.0.0.1 port:9999. java.rmi.ConnectException: Connection refused to host: 127.0.0.1;; nested exception is: 
```

#### 2.3.2、解决方案

开启JMX，开启流程如下：

1、修改kafka的bin目录下面的：`kafka-server-start.sh`文件

```bash
# 在这个下面增加JMX端口的配置
if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G"    
    export JMX_PORT=9999  # 增加这个配置, 这里的数值并不一定是要9999 
fi
```

2、修改kafka的bin目录下面对的：`kafka-run-class.sh`文件

```bash
# JMX settings 
if [ -z "$KAFKA_JMX_OPTS" ]; then
    KAFKA_JMX_OPTS="-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=${当前机器的IP}" 
fi  

# JMX port to use 
if [  $JMX_PORT ]; then
    KAFKA_JMX_OPTS="$KAFKA_JMX_OPTS -Dcom.sun.management.jmxremote.port=$JMX_PORT -Dcom.sun.management.jmxremote.rmi.port=$JMX_PORT" 
fi
```

3、重启Kafka-Broker。


---


### 2.4、异因三：JMX开启SSL

#### 2.4.1、异常现象

```log
# 连接JMX的日志中，出现SSL认证失败的相关日志。TODO：欢迎补充具体日志案例。
```

#### 2.4.2、解决方案

<img src=http://img-ys011.didistatic.com/static/dc2img/do1_kNyCi8H9wtHSRkWurB6S width="50%">


---


### 2.5、异因四：连接了错误IP

#### 2.5.1、异常现象

Broker 配置了内外网，而JMX在配置时，可能配置了内网IP或者外网IP，此时`KnowStreaming` 需要连接到特定网络的IP才可以进行访问。

 比如：Broker在ZK的存储结构如下所示，我们期望连接到 `endpoints` 中标记为 `INTERNAL` 的地址，但是 `KnowStreaming` 却连接了 `EXTERNAL` 的地址。

```json
{
    "listener_security_protocol_map": {
        "EXTERNAL": "SASL_PLAINTEXT",
        "INTERNAL": "SASL_PLAINTEXT"
    },
    "endpoints": [
        "EXTERNAL://192.168.0.1:7092",
        "INTERNAL://192.168.0.2:7093"
    ],
    "jmx_port": 8099,
    "host": "192.168.0.1",
    "timestamp": "1627289710439",
    "port": -1,
    "version": 4
}
```

#### 2.5.2、解决方案

可以手动往`ks_km_physical_cluster`表的`jmx_properties`字段增加一个`useWhichEndpoint`字段，从而控制 `KnowStreaming` 连接到特定的JMX IP及PORT。

`jmx_properties`格式：

```json
{
    "maxConn": 100, // KM对单台Broker的最大JMX连接数   
    "username": "xxxxx", //用户名，可以不填写   
    "password": "xxxx", // 密码，可以不填写    
    "openSSL": true, //开启SSL, true表示开启ssl, false表示关闭    
    "useWhichEndpoint": "EXTERNAL" //指定要连接的网络名称，填写EXTERNAL就是连接endpoints里面的EXTERNAL地址
}
```



SQL例子：

```sql
UPDATE ks_km_physical_cluster SET jmx_properties='{ "maxConn": 10, "username": "xxxxx", "password": "xxxx", "openSSL": false , "useWhichEndpoint": "xxx"}' where id={xxx};
```


---









## 3、ElasticSearch问题

**背景：**
`KnowStreaming` 将从 Kafka 中采集到的指标存储到 ES 中，如果 ES 存在问题，则也可能会导致页面出现无数据的情况。

**日志：**
`KnowStreaming`  读写 ES 相关日志，在 `logs/es/es.log` 中！


**注意：**
mac系统在执行curl指令时，可能报zsh错误。可参考以下操作。

```bash
1 进入.zshrc 文件 vim ~/.zshrc 
2.在.zshrc中加入 setopt no_nomatch 
3.更新配置 source ~/.zshrc
```

---

### 3.1、异因一：缺少索引

#### 3.1.1、异常现象

报错信息

```log
# 日志位置 logs/es/es.log
com.didiglobal.logi.elasticsearch.client.model.exception.ESIndexNotFoundException: method [GET], host[http://127.0.0.1:9200], URI [/ks_kafka_broker_metric_2022-10-21,ks_kafka_broker_metric_2022-10-22/_search], status line [HTTP/1.1 404 Not Found]
```


`curl http://{ES的IP地址}:{ES的端口号}/_cat/indices/ks_kafka*`  查看KS索引列表，发现没有索引。

#### 3.1.2、解决方案

执行 [ES索引及模版初始化](https://github.com/didi/KnowStreaming/blob/master/bin/init_es_template.sh) 脚本，来创建索引及模版。


---


### 3.2、异因二：索引模板错误

#### 3.2.1、异常现象

多集群列表有数据，集群详情页图标无数据。查询KS索引模板列表，发现不存在。

```bash
curl {ES的IP地址}:{ES的端口号}/_cat/templates/ks_kafka*?v&h=name 
```

正常KS模板如下图所示。

<img src=http://img-ys011.didistatic.com/static/dc2img/do1_l79bPYSci9wr6KFwZDA6 width="90%">



#### 3.2.2、解决方案

删除KS索引模板和索引

```bash
curl -XDELETE {ES的IP地址}:{ES的端口号}/ks_kafka*
curl -XDELETE {ES的IP地址}:{ES的端口号}/_template/ks_kafka*
```

执行 [ES索引及模版初始化](https://github.com/didi/KnowStreaming/blob/master/bin/init_es_template.sh) 脚本，来创建索引及模版。


---


### 3.3、异因三：集群Shard满

#### 3.3.1、异常现象

报错信息

```log
# 日志位置 logs/es/es.log

{"error":{"root_cause":[{"type":"validation_exception","reason":"Validation Failed: 1: this action would add [4] total shards, but this cluster currently has [1000]/[1000] maximum shards open;"}],"type":"validation_exception","reason":"Validation Failed: 1: this action would add [4] total shards, but this cluster currently has [1000]/[1000] maximum shards open;"},"status":400}
```

尝试手动创建索引失败。

```bash
#创建ks_kafka_cluster_metric_test索引的指令
curl -s  -XPUT http://{ES的IP地址}:{ES的端口号}/ks_kafka_cluster_metric_test
```


#### 3.3.2、解决方案

ES索引的默认分片数量为1000，达到数量以后，索引创建失败。

+ 扩大ES索引数量上限，执行指令

```
curl -XPUT  -H"content-type:application/json" http://{ES的IP地址}:{ES的端口号}/_cluster/settings -d '
{
  "persistent": {
    "cluster": {
      "max_shards_per_node":{索引上限，默认为1000, 测试时可以将其调整为10000}
    }
  }
}'
```

执行 [ES索引及模版初始化](https://github.com/didi/KnowStreaming/blob/master/bin/init_es_template.sh) 脚本，来补全索引。


